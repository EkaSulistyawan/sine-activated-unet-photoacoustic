{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 26 00:09:21 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.80                 Driver Version: 576.80         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5080      WDDM  |   00000000:02:00.0  On |                  N/A |\n",
      "|  0%   52C    P8             27W /  360W |    2272MiB /  16303MiB |      8%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2652    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A            3904    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A            4520    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            5292    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A            9672    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           10320    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10488    C+G   ...l\\slack\\app-4.44.65\\slack.exe      N/A      |\n",
      "|    0   N/A  N/A           10676    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10884    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           10900    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           10948    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11104    C+G   ...2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A           12548    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           12572    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13216    C+G   ....0.3351.95\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           13908    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           14780    C+G   ....0.3351.95\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19416    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           19888    C+G   ...l\\slack\\app-4.44.65\\slack.exe      N/A      |\n",
      "|    0   N/A  N/A           20100    C+G   ...64__8wekyb3d8bbwe\\Copilot.exe      N/A      |\n",
      "|    0   N/A  N/A           21176    C+G   ...ce\\root\\Office16\\POWERPNT.EXE      N/A      |\n",
      "|    0   N/A  N/A           23648    C+G   ...SnippingTool\\SnippingTool.exe      N/A      |\n",
      "|    0   N/A  N/A           24012      C   ...s\\Python\\Python312\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           24440    C+G   ...yb3d8bbwe\\Notepad\\Notepad.exe      N/A      |\n",
      "|    0   N/A  N/A           33632      C   ...s\\Python\\Python312\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           37316    C+G   ...p\\app-3.5.2\\GitHubDesktop.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import hilbert, butter, filtfilt, freqz, lfilter\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import Lasso\n",
    "import itertools\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from scipy.linalg import toeplitz, circulant\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "from io import BytesIO\n",
    "import plotly.io as pio\n",
    "from ipywidgets import interactive, Layout, FloatSlider, IntSlider, VBox, HBox, interactive_output,ToggleButton,Dropdown,Button\n",
    "import re\n",
    "import mat73\n",
    "import torch.nn.functional as F\n",
    "# # Manually run garbage collection\n",
    "! nvidia-smi\n",
    "\n",
    "\n",
    "# def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "#     b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "#     return b, a\n",
    "\n",
    "# def butter_bandpass_filter(data, lowcut, highcut, fs, order=6):\n",
    "#     b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "#     y = filtfilt(b, a, data, axis=1)\n",
    "#     return y\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fc      = 15.625e6                            \n",
    "Fs      = 4*Fc                       \n",
    "ntime   = 3072\n",
    "dt      = 1/Fs\n",
    "rtrans  = 30            # mm\n",
    "b       = 1e-3          # m, half width trans\n",
    "beta    = 1e-3          # m, half height trans\n",
    "device  ='cuda'\n",
    "imsz    = 86 # leaf use 86 \n",
    "r       = 1.0\n",
    "rix, riy, riz = np.meshgrid(\n",
    "    np.linspace(-r, r, imsz),\n",
    "    np.linspace(-r, r, imsz),\n",
    "    np.linspace(-r, r, imsz), # - 0.5 # for invivo PalmRightHand2\n",
    "    indexing='ij'\n",
    ")\n",
    "rix = torch.tensor(rix, dtype=torch.float32).to(device)\n",
    "riy = torch.tensor(riy, dtype=torch.float32).to(device)\n",
    "riz = torch.tensor(riz, dtype=torch.float32).to(device)\n",
    "\n",
    "# rotate along z direction\n",
    "\n",
    "\n",
    "global volPA\n",
    "volPA = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for leaf546 dont use this\n",
    "# theta = -np.pi / 4  # 45 degrees\n",
    "# cos_theta = np.cos(theta)\n",
    "# sin_theta = np.sin(theta)\n",
    "\n",
    "# # Perform 45-degree rotation in the xy-plane\n",
    "# rix_rot = cos_theta * rix - sin_theta * riy\n",
    "# riy_rot = sin_theta * rix + cos_theta * riy\n",
    "\n",
    "# # Convert the rotated coordinates back to tensors\n",
    "# rix = (rix_rot).to(device)\n",
    "# riy = (riy_rot).to(device)\n",
    "\n",
    "# # The z-coordinates remain unchanged\n",
    "# riz = riz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rotate matrix rotate the initial_vector to the target_vector\n",
    "# It outputs the transformation matrix which we will use to rotate the imaging\n",
    "# plane as well\n",
    "def rot_matrix_arb(initial_vector,\n",
    "                   target_vector=torch.tensor([0,0,rtrans],dtype=torch.float).to(device)):\n",
    "    # Calculate the rotation axis (cross product) and normalize it\n",
    "    rotation_axis = torch.cross(initial_vector.squeeze(), target_vector.squeeze(),dim=0)\n",
    "    rotation_axis = rotation_axis / torch.norm(rotation_axis)\n",
    "\n",
    "    # Calculate the rotation angle (in radians)\n",
    "    rotation_angle = torch.acos(\n",
    "        torch.dot(initial_vector, target_vector) /\n",
    "        (torch.norm(initial_vector) * torch.norm(target_vector))\n",
    "    )\n",
    "\n",
    "    # Construct the rotation matrix using the axis-angle formula\n",
    "    K = torch.tensor([\n",
    "        [0, -rotation_axis[2], rotation_axis[1]],\n",
    "        [rotation_axis[2], 0, -rotation_axis[0]],\n",
    "        [-rotation_axis[1], rotation_axis[0], 0]\n",
    "    ]).to(device)\n",
    "\n",
    "    # Identity matrix\n",
    "    I = torch.eye(3).to(device)\n",
    "\n",
    "    # Rotation matrix formula: R = I + sin(angle) * K + (1 - cos(angle)) * K^2\n",
    "    # R_matrix = I + torch.sin(rotation_angle) * K + (1 - torch.cos(rotation_angle)) * (K @ K)\n",
    "    # Rodrigues's First Formula\n",
    "    rrmat = torch.cos(rotation_angle) * I + torch.sin(rotation_angle) * K + (1 - torch.cos(rotation_angle)) * (rotation_axis.unsqueeze(1) @ rotation_axis.unsqueeze(1).T)\n",
    "\n",
    "    return rrmat\n",
    "\n",
    "\n",
    "def rotate_matrix_twice(initial_vector):\n",
    "    # rotate to the center\n",
    "    target_vector = torch.tensor([0,0,rtrans],dtype=torch.float).to(device)\n",
    "\n",
    "    # Calculate the rotation axis (cross product) and normalize it\n",
    "    rotation_axis = torch.cross(initial_vector.squeeze(), target_vector.squeeze(),dim=0)\n",
    "    rotation_axis = rotation_axis / torch.norm(rotation_axis)\n",
    "\n",
    "    # Calculate the rotation angle (in radians)\n",
    "    rotation_angle = torch.acos(\n",
    "        torch.dot(initial_vector, target_vector) /\n",
    "        (torch.norm(initial_vector) * torch.norm(target_vector))\n",
    "    )\n",
    "\n",
    "    # Construct the rotation matrix using the axis-angle formula\n",
    "    K = torch.tensor([\n",
    "        [0, -rotation_axis[2], rotation_axis[1]],\n",
    "        [rotation_axis[2], 0, -rotation_axis[0]],\n",
    "        [-rotation_axis[1], rotation_axis[0], 0]\n",
    "    ]).to(device)\n",
    "\n",
    "    # Identity matrix\n",
    "    I = torch.eye(3).to(device)\n",
    "\n",
    "    # Rotation matrix formula: R = I + sin(angle) * K + (1 - cos(angle)) * K^2\n",
    "    # R_matrix = I + torch.sin(rotation_angle) * K + (1 - torch.cos(rotation_angle)) * (K @ K)\n",
    "    # Rodrigues's First Formula\n",
    "    rrtocenter = torch.cos(rotation_angle) * I + torch.sin(rotation_angle) * K + (1 - torch.cos(rotation_angle)) * (rotation_axis.unsqueeze(1) @ rotation_axis.unsqueeze(1).T)\n",
    "\n",
    "    # rotation to align  the xy coordinates\n",
    "    angle_ = - torch.arctan(initial_vector[1]/initial_vector[0])\n",
    "    rrxy = torch.tensor([\n",
    "        [torch.cos(angle_)  ,-torch.sin(angle_)  ,0],\n",
    "        [torch.sin(angle_)  , torch.cos(angle_)  ,0],\n",
    "        [0                  , 0                  ,1]\n",
    "    ]).to(device)\n",
    "\n",
    "\n",
    "    return rrxy @ rrtocenter\n",
    "\n",
    "def get_directivity(idx,params):\n",
    "    # the rotate matrix twice \n",
    "    # 1. rotate the whole field directly [0, 0, rtrans]\n",
    "    # 2. rotate the whole field depending on the orientation of the element, i.e., make it normal to x and y\n",
    "    rr      = rotate_matrix_twice(params[\"SENSOR_POS\"][:, idx]) @ torch.vstack([rix.ravel(),riy.ravel(),riz.ravel()]) # operation in m\n",
    "    # print(rr.shape)\n",
    "\n",
    "    # get directivity, rotri: rotated coordinate ri\n",
    "    rotrix  = (rr[0].reshape(imsz,imsz,imsz))            * 1e-3           # in m\n",
    "    rotriy  = (rr[1].reshape(imsz,imsz,imsz))            * 1e-3           # in m\n",
    "    rotriz  = (rr[2].reshape(imsz,imsz,imsz) - rtrans)   * 1e-3           # in m, transpose to 0\n",
    "\n",
    "    # print(rotrix.shape)\n",
    "\n",
    "\n",
    "    # from Damien Garcia's SIMUS3 Paper\n",
    "    k           = 2*torch.pi*Fc/(params['cPA'])\n",
    "    rrr         = torch.sqrt(rotrix.square() + rotriy.square()+ rotriz.square())\n",
    "    sinphi      = rotriy                                        / torch.sqrt(rotrix.square() + rotriy.square())\n",
    "    cosphi      = rotrix                                        / torch.sqrt(rotrix.square() + rotriy.square())\n",
    "    sintheta    = torch.sqrt(rotrix.square() + rotriy.square()) / rrr\n",
    "\n",
    "    # torch's sinc is normalized: sin(pi x) /( pi x)\n",
    "    # we want it unnormalized\n",
    "    Dx = torch.sinc(k * b    * cosphi * sintheta / torch.pi)\n",
    "    Dy = torch.sinc(k * beta * sinphi * sintheta / torch.pi)\n",
    "\n",
    "    # from Cobbold's book\n",
    "    # l_lambda    = cPA/(2*torch.pi*Fc)\n",
    "    # sintheta    = rotrix / torch.sqrt(rotrix.square() + rotriy.square()+ rotriz.square())\n",
    "    # sinphi      = rotriy / torch.sqrt(rotrix.square() + rotriy.square()+ rotriz.square())\n",
    "    # W           = 2*b         \n",
    "    # H           = 2*beta\n",
    "\n",
    "    # # Sinc in pytorch is normalized\n",
    "    # Dx = torch.sinc(W *  sintheta /(l_lambda * torch.pi))\n",
    "    # Dy = torch.sinc(H *  sinphi   /(l_lambda * torch.pi))\n",
    "\n",
    "    #D = torch.sqrt(Dx.abs().square() + Dy.abs().square())\n",
    "    D = Dx * Dy\n",
    "\n",
    "    return D\n",
    "\n",
    "def hilbert_torch(signal, dim=-1):\n",
    "    \"\"\"\n",
    "    Computes the Hilbert transform of a multi-dimensional signal using the Fast Fourier Transform (FFT).\n",
    "    This implementation mimics MATLAB's hilbert function.\n",
    "\n",
    "    Args:\n",
    "        signal (torch.Tensor): The input n-dimensional tensor (signal) to transform.\n",
    "        dim (int): The dimension along which to compute the Hilbert transform.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The complex-valued Hilbert transform (analytic signal) of the input signal.\n",
    "    \"\"\"\n",
    "    # Ensure the input is a tensor\n",
    "    if not isinstance(signal, torch.Tensor):\n",
    "        raise ValueError(\"Input must be a PyTorch tensor.\")\n",
    "\n",
    "    # Get the shape of the input tensor\n",
    "    shape = signal.shape\n",
    "\n",
    "    # Move the tensor to GPU if available\n",
    "    device = signal.device\n",
    "    N = signal.size(dim)\n",
    "\n",
    "    # Compute the FFT along the specified dimension\n",
    "    transforms = torch.fft.fft(signal, dim=dim)\n",
    "\n",
    "    # Create a mask to apply to the FFT results\n",
    "    mask = torch.zeros(N, dtype=torch.complex64, device=device)\n",
    "    mask[0] = 1  # DC component remains unchanged\n",
    "    mask[1:N//2] = 2  # Double the amplitude for positive frequencies\n",
    "    if N % 2 == 0:\n",
    "        mask[N//2] = 1  # Include the Nyquist frequency if even\n",
    "\n",
    "    # Apply the mask to the FFT of the signal\n",
    "    transforms = transforms * mask\n",
    "\n",
    "    # Compute the inverse FFT to get the Hilbert transform (analytic signal)\n",
    "    hilbert_signal = torch.fft.ifft(transforms, dim=dim)\n",
    "\n",
    "    return hilbert_signal\n",
    "\n",
    "def fk_filter(test):\n",
    "    ntime = test.shape[0]\n",
    "    nsensor = test.shape[1]\n",
    "    nseg = 4\n",
    "    #\n",
    "    test = test.reshape(ntime,nseg,-1).permute(1,2,0)\n",
    "    testft = torch.fft.fftshift(torch.fft.fft2(test),dim=(1,2))\n",
    "    testft[:,32,:] = 0\n",
    "\n",
    "    rec = torch.fft.ifft2(torch.fft.ifftshift(testft,dim=(1,2))).permute(2,0,1).reshape(ntime,nsensor).real\n",
    "\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from VRS\n",
    "import struct\n",
    "def load_vrs(fileName,nt,ntx=28,verbose=False):\n",
    "    headerInfo = {}\n",
    "    with open(fileName, 'rb') as file_obj:\n",
    "        # Read Version (uint16)\n",
    "        version = struct.unpack('3B', file_obj.read(3))[0]  # Read 2 bytes for uint16\n",
    "        headerInfo['version'] = version\n",
    "        # Compression (uint8)\n",
    "        compression = struct.unpack('B', file_obj.read(1))[0]\n",
    "        headerInfo['compression'] = compression\n",
    "\n",
    "        timetagflag = struct.unpack('B', file_obj.read(1))[0]\n",
    "        headerInfo['timetagflag'] = timetagflag\n",
    "\n",
    "    #     so no timetagflag\n",
    "        if timetagflag == 1:\n",
    "            time_tag = struct.unpack('6B', file_obj.read(6))  # 6 bytes: Sec, Min, Hour, Day, Month, Year\n",
    "            headerInfo['time_tag'] = time_tag\n",
    "\n",
    "        studyidlength = struct.unpack('<Q', file_obj.read(8))[0]\n",
    "        headerInfo['studyidlength'] = studyidlength\n",
    "        studyid = file_obj.read(studyidlength).decode('utf-8')\n",
    "        headerInfo['studyid'] = studyid\n",
    "\n",
    "        sampleidlength = struct.unpack('<Q', file_obj.read(8))[0]\n",
    "        headerInfo['sampleidlength'] = sampleidlength\n",
    "        sampleid = file_obj.read(sampleidlength).decode('utf-8')\n",
    "        headerInfo['sampleid'] = sampleid\n",
    "\n",
    "        commentlength = struct.unpack('<Q', file_obj.read(8))[0]\n",
    "        headerInfo['commentlength'] = commentlength\n",
    "        comment = file_obj.read(commentlength).decode('utf-8')\n",
    "        headerInfo['comment'] = comment\n",
    "\n",
    "        dim = struct.unpack('4Q', file_obj.read(32))  # 4 uint64 values\n",
    "        headerInfo['dim'] = dim\n",
    "\n",
    "        numdatapoints = struct.unpack('Q', file_obj.read(8))[0]\n",
    "        headerInfo['numdatapoints'] = numdatapoints\n",
    "\n",
    "        #print(file_obj.read(1))\n",
    "        datatypes = struct.unpack('B', file_obj.read(1))[0]\n",
    "        headerInfo['datatypes'] = datatypes\n",
    "\n",
    "        # not sure what is this dtypes version\n",
    "        # in the actual extraction, it shows S16, probably signed 16\n",
    "\n",
    "        data = np.frombuffer(file_obj.read(numdatapoints * 2), dtype='<h')  # 2 bytes per int16\n",
    "        data2 = np.reshape(data ,(dim[1],ntx*3072)) #  the initial data is flattened time with the amount of TX, for each sensor, they store the data in 4096 format\n",
    "        data2 = np.reshape(data2[:,:ntx*nt],(dim[1],ntx,nt))\n",
    "\n",
    "    if verbose:\n",
    "        for key in headerInfo.keys():\n",
    "            print(key,headerInfo[key])\n",
    "    return data2\n",
    "\n",
    "def load_vrs_data(pathFileName,datanum=20):\n",
    "    data = load_vrs(pathFileName,3072,datanum,verbose=False)\n",
    "    data = data.transpose(1,2,0)\n",
    "    data = np.expand_dims(data,-1)\n",
    "    # data should be (nsensor, ntime)\n",
    "    # play around here \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sensor_PA(idx_rcv,datPAraw,sensor_pos_local,cPA,start_time_PA,params,with_directivity=False):\n",
    "    # Receive\n",
    "    dPos_rcv = sensor_pos_local[:, idx_rcv]\n",
    "    phys_dist_rcv = torch.sqrt((rix - dPos_rcv[0]) ** 2 + (riy - dPos_rcv[1]) ** 2 + (riz - dPos_rcv[2]) ** 2)\n",
    "\n",
    "    time_points_distPA = ((phys_dist_rcv) * 1e-3 / cPA) * Fs - start_time_PA # this is the time\n",
    "\n",
    "    phase_rotator = torch.exp(-1j * 2 * torch.pi * (phys_dist_rcv * 1e-3 / cPA) * Fc)\n",
    "    \n",
    "    linear_factor = (time_points_distPA -  torch.floor(time_points_distPA))\n",
    "    data_slicePA = (datPAraw[idx_rcv, torch.floor(time_points_distPA).to(torch.int32)] \n",
    "                    + linear_factor*(\n",
    "                        datPAraw[idx_rcv, torch.ceil(time_points_distPA).to(torch.int32)]\n",
    "                        - datPAraw[idx_rcv, torch.floor(time_points_distPA).to(torch.int32)]\n",
    "                    ))\n",
    "    \n",
    "    if with_directivity:\n",
    "        D = get_directivity(idx_rcv,params)\n",
    "        return D * data_slicePA\n",
    "    else:\n",
    "        return data_slicePA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthImage(volume,idx,isShow=False,isReturn=False):\n",
    "\n",
    "    # Step 1: Project depth data to create a depth map\n",
    "    depth_map = np.argmax(volume, axis=2)\n",
    "\n",
    "    # Step 2: Normalize the depth data for color mapping\n",
    "    # depth_normalized = (depth_map - np.min(depth_map)) / (np.max(depth_map) - np.min(depth_map))\n",
    "    depth_normalized = depth_map / imsz\n",
    "    depth_normalized = 1 - abs(depth_normalized*2 - 1)\n",
    "\n",
    "    # Step 3: Create an intensity map for coloring\n",
    "    # Use the maximum intensity along the depth (z-axis) for each (x, y) location\n",
    "    intensity_map = np.max(volume, axis=2)\n",
    "\n",
    "    # Normalize intensity values to range [0, 1]\n",
    "    intensity_normalized = (intensity_map - np.min(intensity_map)) / (np.max(intensity_map) - np.min(intensity_map))\n",
    "\n",
    "    # Step 5: Apply the 'hot' colormap to the depth map using plt.get_cmap\n",
    "    colormap = plt.get_cmap('hot')\n",
    "    depth_colored = colormap(depth_normalized)\n",
    "\n",
    "    # Step 6: Scale the colormap by intensity (for darkness effect)\n",
    "    depth_colored[..., :3] = depth_colored[..., :3] * intensity_normalized[..., np.newaxis]  # Apply intensity to RGB channels\n",
    "\n",
    "    \n",
    "    \n",
    "    # depth_colored = np.flipud(depth_colored)\n",
    "    # depth_colored = np.rot90(depth_colored)\n",
    "    if isReturn:\n",
    "        return depth_colored\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(depth_colored,cmap='hot')\n",
    "\n",
    "    # Add the colorbar with the same 'hot' colormap\n",
    "    cbar = fig.colorbar(im, ax=ax, cmap='hot')  # Explicitly set the colormap for the colorbar\n",
    "    cbar.set_label('Depth (mm), Surface @ 0 mm ')  # Customize the label as needed\n",
    "    cbar.set_ticks(np.linspace(0,1,5))  # Set the tick positions\n",
    "    cbar.set_ticklabels([f\"{x:.1f}\" for x in np.linspace(-r,-0.45,5)])  # Set the tick positions minus offset of surface location by US\n",
    "    # Display the plot\n",
    "    # ax.axis('off')  # Turn off axis\n",
    "    plt.xticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(-r,r,5)])\n",
    "    plt.yticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(r,-r,5)])\n",
    "\n",
    "    ax.text(0.95, 0.05, f\"{(idx * (1/20)):.2f} s\", color='white', fontsize=12, ha='right', va='bottom',\n",
    "            transform=ax.transAxes, bbox=dict(facecolor='black', alpha=0.5))\n",
    "\n",
    "    if isShow:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(os.path.expanduser(f'~/Documents/images/{idx}.png'),bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "def SliceImageZ(slice,idx,vmin=0,vmax=1,isShow=False):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    slice = np.rot90(slice)\n",
    "    im = ax.imshow(slice,cmap='hot',vmin=vmin,vmax=vmax)\n",
    "\n",
    "    # Add the colorbar with the same 'hot' colormap\n",
    "    cbar = fig.colorbar(im, ax=ax, cmap='hot')  # Explicitly set the colormap for the colorbar\n",
    "    # cbar.set_label('Depth (mm), Surface @ 0 mm ')  # Customize the label as needed\n",
    "    # cbar.set_ticks(np.linspace(0,1,5))  # Set the tick positions\n",
    "    # cbar.set_ticklabels([f\"{x:.1f}\" for x in np.linspace(-r,-0.45,5)])  # Set the tick positions minus offset of surface location by US\n",
    "    # Display the plot\n",
    "    # ax.axis('off')  # Turn off axis\n",
    "    plt.xticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(-r,r,5)])\n",
    "    plt.yticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(r,-r,5)])\n",
    "\n",
    "    ax.text(0.95, 0.05, f\"{(idx * (1/20)):.2f} s\", color='white', fontsize=12, ha='right', va='bottom',\n",
    "            transform=ax.transAxes, bbox=dict(facecolor='black', alpha=0.5))\n",
    "\n",
    "    if isShow:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(os.path.expanduser(f'~/Documents/images/{idx}.png'),bbox_inches='tight')\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickPAbeamform(datPA,params):\n",
    "    global prediction, CF\n",
    "    datPA = torch.tensor(datPA,dtype=torch.float)\n",
    "\n",
    "    isbackprojection    = params['is_UBP']\n",
    "    iswiener            = params['is_WIENER']\n",
    "    isdirectivity       = params['is_DIRECTIVITY']\n",
    "    wienermethod        = params['WIENER_METHOD'] # either FREQ or LASSO\n",
    "    reg                 = params['WIENER_REG']\n",
    "    isPostSVD           = params['POST_SVD'] # either FREQ or LASSO\n",
    "    SVDTHPost           = params['POST_SVD_THS']\n",
    "    BEAMFORMING_TYPE    = params['BEAMFORM_TYPE']\n",
    "    isCF                = params['is_CF']\n",
    "    sensor_pos_loc      = params['SENSOR_POS']\n",
    "    cPA                 = params['cPA']\n",
    "    start_time_PA       = params['start_time_PA']\n",
    "    end_time_PA         = params['end_time_PA']\n",
    "    # for 4 times larger time signal : e-6, e-7, e-8\n",
    "    # for 4 times larger signal, FREQ Wiener use 1e-1 to 1e-3\n",
    "    # if wiener filter, no need to \n",
    "\n",
    "    # this is the default\n",
    "    try:\n",
    "        CFmethod            = params['CFmethod']\n",
    "    except:\n",
    "        CFmethod            = 'CF'\n",
    "\n",
    "    if iswiener:\n",
    "        datPA = torch.tensor(\n",
    "            wiener_conv(datPA.T,psf,wienermethod,noisefloor,reg),\n",
    "            dtype=torch.cfloat\n",
    "            )\n",
    "        prediction = datPA.real\n",
    "    else:\n",
    "        datPA = hilbert_torch(datPA,1)\n",
    "\n",
    "    # if backprojection\n",
    "    if isbackprojection:\n",
    "        datPA = datPA - (torch.roll(datPA,-1,1) - torch.roll(datPA,1,1))*0.5*torch.arange(datPA.shape[1])\n",
    "\n",
    "    \n",
    "    if isPostSVD:\n",
    "        datPA = torch.tensor(PostSVDFilter(datPA,SVDTHPost),dtype=torch.cfloat)\n",
    "\n",
    "\n",
    "    # move to device efficiently\n",
    "    datPA = datPA.to(device)\n",
    "\n",
    "    \n",
    "    # PA beamforming\n",
    "    volPA            = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "    # volPAunsum       = torch.zeros((256,imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "    if (CFmethod == \"PCF\") or (CFmethod == 'CCF'):\n",
    "        CF               = torch.zeros((imsz, imsz, imsz), dtype=torch.float).to(device)\n",
    "        CF2              = torch.zeros((imsz, imsz, imsz), dtype=torch.float).to(device)\n",
    "    else:\n",
    "        CF               = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "\n",
    "\n",
    "    # for C. Kim implemetation\n",
    "    # Sroot    = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "    # Sabs     = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "    # Ssquare  = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "\n",
    "        \n",
    "    # Main execution DAS\n",
    "    if BEAMFORMING_TYPE == 'DAS':\n",
    "        total_iter = 0\n",
    "        for i in (range(256)): # i is n\n",
    "            \n",
    "            # for das we have just one\n",
    "            padat = process_sensor_PA(i,datPA,sensor_pos,cPA,start_time_PA,params,isdirectivity) # this one is Sdelay\n",
    "            volPA += padat\n",
    "\n",
    "            phase = torch.arctan2(padat.imag, padat.real)\n",
    "            if CFmethod == 'CF':\n",
    "                \n",
    "                # CF += padat.real.abs() + 1j*padat.imag.abs()\n",
    "                CF += padat.abs()**2\n",
    "            elif CFmethod == 'SCF':\n",
    "                CF += torch.sign(padat.real)\n",
    "\n",
    "            elif (CFmethod == 'PCF'):\n",
    "                CF += phase # CF here is for calculating the mean\n",
    "\n",
    "            elif (CFmethod == 'CCF'):\n",
    "                CF  += torch.cos(phase) # CF is to record the mean later\n",
    "                CF2 += torch.sin(phase) # CF2 is to record the mean later\n",
    "            \n",
    "\n",
    "\n",
    "    if 'INTERP' in BEAMFORMING_TYPE:\n",
    "        total_iter = 0\n",
    "        for i in (range(511)):\n",
    "            \n",
    "            # for das we have just one\n",
    "            padat = process_sensor_PA(i,datPA,sensor_pos_interp,cPA,start_time_PA,params,isdirectivity)\n",
    "            volPA += padat\n",
    "            # CF += padat.real.abs() + 1j*padat.imag.abs()\n",
    "            CF += padat.abs()\n",
    "\n",
    "\n",
    "\n",
    "    # if follow this paper: https://ieeexplore.ieee.org/document/9812728\n",
    "    # they actually cite Chulhong Kim's paper: https://www.sciencedirect.com/science/article/pii/S2213597919300023#sec0070\n",
    "    # but the IEEE implementation is way differ\n",
    "\n",
    "    # # IEEE's \n",
    "    # if BEAMFORMING_TYPE == 'DMAS-INTERP':\n",
    "    #     total_iter = 0\n",
    "    #     SumOfSquared     = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "    #     SquaredOfSum     = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "    #     for i in tqdm(range(256)):\n",
    "    #         padat = process_sensor_PA(i,datPA,sensor_pos_interp,cPA,start_time_PA,params,isdirectivity)\n",
    "    #         SumOfSquared += (torch.sgn(padat) * padat.abs().sqrt())**2\n",
    "    #         SquaredOfSum += (torch.sgn(padat) * padat.abs().sqrt())\n",
    "    #         # SumOfSquared += (padat)**2\n",
    "    #         # SquaredOfSum += (padat)\n",
    "    #     SquaredOfSum = SquaredOfSum**2\n",
    "    #     volPA = (SquaredOfSum - SumOfSquared) / 2\n",
    "\n",
    "    # if BEAMFORMING_TYPE == 'DMAS':\n",
    "    #     total_iter = 0\n",
    "    #     SumOfSquared     = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "    #     SquaredOfSum     = torch.zeros((imsz, imsz, imsz), dtype=torch.cfloat).to(device)\n",
    "    #     for i in tqdm(range(256)):\n",
    "    #         padat = process_sensor_PA(i,datPA,sensor_pos,cPA,start_time_PA,params,isdirectivity)\n",
    "    #         SumOfSquared += (torch.sgn(padat) * padat.abs().sqrt())**2\n",
    "    #         SquaredOfSum += (torch.sgn(padat) * padat.abs().sqrt())\n",
    "    #         # SumOfSquared += (padat)**2\n",
    "    #         # SquaredOfSum += (padat)\n",
    "    #     SquaredOfSum = SquaredOfSum**2\n",
    "    #     volPA = (SquaredOfSum - SumOfSquared) / 2\n",
    "\n",
    "    # # main execution DMAS\n",
    "    # if BEAMFORMING_TYPE == 'DMAS-CF':\n",
    "\n",
    "    #     for i in tqdm(range(256)):\n",
    "    #         padat = process_sensor_PA(i,datPA,cPA,start_time_PA,params,isdirectivity)\n",
    "\n",
    "    #         Sroot   += torch.sgn(padat) * padat.abs().sqrt()\n",
    "    #         Sabs    += padat.abs()\n",
    "    #         Ssquare += padat.square()\n",
    "\n",
    "    #     N = 256\n",
    "    #     volPA = (Sroot.square()-Sabs)**3 * (2*N*(N-1)) / (Sabs.square() - Ssquare)\n",
    "\n",
    "    if (isCF) and (CFmethod == 'CF'):\n",
    "        # volPA = volPA.real * volPA.real**2 / (256 * CF.real) +  1j * volPA.imag * volPA.imag**2 / (256 * CF.imag)\n",
    "        CF = abs(volPA)**2 / (sensor_pos.shape[1] * CF)\n",
    "        volPA = volPA * CF\n",
    "    if isCF and (CFmethod == 'SCF'):\n",
    "        sigma = torch.sqrt(1 - (CF/sensor_pos.shape[1])**2)\n",
    "        volPA = volPA * abs(1-sigma)\n",
    "\n",
    "    # if PCF, then U need to redo the computation\n",
    "    if isCF and (CFmethod == 'PCF'):\n",
    "        varb = torch.zeros_like(CF) # this is variable for calculating standard deviation (on PCF)\n",
    "        if BEAMFORMING_TYPE == 'DAS':\n",
    "            total_iter = 0\n",
    "            for i in (range(256)):\n",
    "                \n",
    "                # for das we have just one\n",
    "                padat = process_sensor_PA(i,datPA,sensor_pos,cPA,start_time_PA,params,isdirectivity)\n",
    "                phase = torch.arctan2(padat.imag, padat.real)\n",
    "\n",
    "                varb += (phase - (CF / sensor_pos.shape[1]))**2 # CF is the mean phase we calculated earlier\n",
    "            varb = (varb / sensor_pos.shape[1])**0.5 # here varb is standard deviation\n",
    "            CF = torch.maximum(torch.zeros_like(varb), 1 - varb / (torch.pi / (3**0.5)))\n",
    "            volPA = volPA * CF\n",
    "            # volPA = volPA.real\n",
    "            # volPA = hilbert_torch(volPA)\n",
    "\n",
    "    if isCF and (CFmethod == 'CCF'):\n",
    "        varcos = torch.zeros_like(CF) # this is variable for calculating standard deviation (on PCF)\n",
    "        varsin = torch.zeros_like(CF2) # this is variable for calculating standard deviation (on PCF)\n",
    "        if BEAMFORMING_TYPE == 'DAS':\n",
    "            total_iter = 0\n",
    "            for i in (range(256)):\n",
    "                \n",
    "                # for das we have just one\n",
    "                padat = process_sensor_PA(i,datPA,sensor_pos,cPA,start_time_PA,params,isdirectivity)\n",
    "                phase = torch.arctan2(padat.imag, padat.real)\n",
    "\n",
    "                varcos += (torch.cos(phase) - (CF  / sensor_pos.shape[1]))**2    # CF is the mean phase we calculated earlier, for cos\n",
    "                varsin += (torch.sin(phase) - (CF2 / sensor_pos.shape[1]))**2   # for mean sin\n",
    "\n",
    "            CF =  1 - ((varcos / sensor_pos.shape[1])**2 + (varsin / sensor_pos.shape[1])**2)**0.5\n",
    "            volPA = volPA * CF\n",
    "            # volPA = volPA.real\n",
    "            # volPA = hilbert_torch(volPA)\n",
    "\n",
    "    # what if you do hilbert after beamforming\n",
    "    # volPA = hilbert_torch(volPA.real,-1)\n",
    "        \n",
    "        \n",
    "    return volPA    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fk_filter(test):\n",
    "    ntime = test.shape[0]\n",
    "    nsensor = test.shape[1]\n",
    "    nseg = 4\n",
    "    #\n",
    "    test = test.reshape(ntime,nseg,-1).transpose(1,2,0)\n",
    "    testft = np.fft.fftshift(np.fft.fft2(test),axes=(1,2))\n",
    "    testft[:,32,:] = 0\n",
    "\n",
    "    rec = np.fft.ifft2(np.fft.ifftshift(testft,axes=(1,2))).transpose(2,0,1).reshape(ntime,nsensor).real\n",
    "\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All helpers function stored here\n",
    "def get_psf(x):\n",
    "    mu = abs(np.fft.fft(hilbert_torch(x,1))).T.mean(-1)\n",
    "    psf = np.fft.fftshift(np.fft.ifft(mu))\n",
    "    return psf\n",
    "\n",
    "# the wiener conv solve the deconvolution for x given \n",
    "# the PSF constructed as matrix Ar (real) & Ai (imaginary)\n",
    "# the output is a complex number solution of the deconvolved signal\n",
    "def wiener_conv(y,h,method='LASSO',noise_estimate=0,reg_params=1e-6):\n",
    "    # need to normalize the data first\n",
    "    # y is all real data\n",
    "\n",
    "    if method == 'LASSO':\n",
    "        kernel  = np.fft.fftshift(h)\n",
    "        G       = circulant(kernel)\n",
    "\n",
    "        yinp    = y.numpy()\n",
    "        yinpmax = yinp.max(0)\n",
    "        yinp    = yinp / yinpmax\n",
    "        solReal =  Lasso(alpha=reg_params,max_iter=100000).fit(G.real,yinp).coef_.T * yinpmax\n",
    "\n",
    "        yinp    = y.numpy()\n",
    "        yinpmax = yinp.max(0)\n",
    "        yinp    = yinp / yinpmax\n",
    "        solImag =  Lasso(alpha=reg_params,max_iter=100000).fit(G.imag,yinp).coef_.T * yinpmax\n",
    "\n",
    "        sol = solReal + 1j*solImag\n",
    "\n",
    "        return sol.T\n",
    "\n",
    "        \n",
    "    if method == 'FREQ':\n",
    "        y_max = y.clone().max()\n",
    "        y     = y / y_max\n",
    "        predenum= (abs(np.fft.fft(h) )**2)+ 1e-2\n",
    "        denum   = (abs(np.fft.fft(h))**2 + reg_params * ( abs(np.fft.fft(noise_estimate))**2 / predenum))\n",
    "        denum   = denum + 1e-2\n",
    "\n",
    "        M       = np.fft.fft(h).conj() / denum\n",
    "        PAr     = np.fft.ifftshift(np.fft.ifft( (np.fft.fft(y.T) * M) ),1)\n",
    "\n",
    "        PAr     = PAr * y_max.numpy() / abs(PAr).max()\n",
    "\n",
    "        final_result = PAr\n",
    "\n",
    "    if method == \"TIKHONOV\":\n",
    "        y_raw = y.clone()\n",
    "        y_max = y.max(0).values\n",
    "        y     = y / (y_max)\n",
    "        psf_r = np.real(np.fft.fftshift(h))\n",
    "        psf_i = np.imag(np.fft.fftshift(h))\n",
    "\n",
    "        # construct shif matrix\n",
    "        Ar = toeplitz(psf_r,psf_r)\n",
    "        Ai = toeplitz(psf_i,psf_i)\n",
    "\n",
    "        x_hat_r = np.linalg.inv(Ar.T @ Ar + np.eye(Ar.shape[0])*reg_params) @ Ar.T @ y.numpy()\n",
    "        x_hat_i = np.linalg.inv(Ai.T @ Ai + np.eye(Ai.shape[0])*reg_params) @ Ai.T @ y.numpy()\n",
    "\n",
    "        x_hat = x_hat_r + 1j*x_hat_i\n",
    "\n",
    "        x_hat = (x_hat.T)\n",
    "        final_result = x_hat * y_max.unsqueeze(-1).numpy()\n",
    "\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate the snesor, named \"sensor_pos_interp\"\n",
    "sensor_pos      = np.load(\"./hardware/transducer_coordinates.npy\").T* 1e3 # make mm\n",
    "sensor_pos      = torch.tensor(sensor_pos,dtype=torch.float).to(device)\n",
    "# Initialize the output tensor for interpolated positions\n",
    "sensor_pos_p5 = torch.zeros_like(sensor_pos,dtype=torch.float)\n",
    "\n",
    "# Loop through each pair of consecutive sensors\n",
    "for i in range(sensor_pos.shape[1] - 1):\n",
    "    # Get the vectors for the current and next sensor\n",
    "    v0 = sensor_pos[:, i] / rtrans\n",
    "    v1 = sensor_pos[:, i + 1] / rtrans\n",
    "\n",
    "    # Calculate the angle between the vectors in spherical coordinates (azimuth and elevation)\n",
    "    v0_angle = torch.acos(v0[2])  # Elevation angle for v0 (angle from the z-axis)\n",
    "    v1_angle = torch.acos(v1[2])  # Elevation angle for v1\n",
    "\n",
    "    # Interpolate the elevation angle\n",
    "    vp5_angle = (v0_angle + v1_angle) / 2\n",
    "    zp5 = rtrans * torch.cos(vp5_angle)\n",
    "\n",
    "    # Calculate the azimuth angle (angle in the xy-plane)\n",
    "    rxy_v0 = torch.norm(v0[:2])  # Radius in the xy-plane for v0\n",
    "    rxy_v1 = torch.norm(v1[:2])  # Radius in the xy-plane for v1\n",
    "    v0_azimuth = torch.atan2(v0[1], v0[0])  # Azimuth angle for v0\n",
    "    v1_azimuth = torch.atan2(v1[1], v1[0])  # Azimuth angle for v1\n",
    "\n",
    "    # Interpolate the azimuth angle\n",
    "    vp5_azimuth = (v0_azimuth + v1_azimuth) / 2\n",
    "\n",
    "    # Calculate the x and y components of the interpolated point\n",
    "    xp5 = rxy_v0 * torch.cos(vp5_azimuth) * rtrans\n",
    "    yp5 = rxy_v0 * torch.sin(vp5_azimuth) * rtrans\n",
    "\n",
    "    # Combine the interpolated coordinates\n",
    "    p5 = torch.tensor([xp5, yp5, zp5], dtype=torch.float)\n",
    "\n",
    "    # Store the interpolated position\n",
    "    sensor_pos_p5[:, i] = p5\n",
    "\n",
    "sensor_pos_interp = torch.zeros((sensor_pos.shape[0],2*sensor_pos.shape[1]-1))\n",
    "sensor_pos_interp[:,::2] = sensor_pos               # evezn number is the actual data\n",
    "# correct z\n",
    "track_change = torch.tensor([51, 99, 143, 179, 211, 235, 255],dtype=torch.int)\n",
    "sensor_pos_p5[2,track_change] = sensor_pos_p5[2,track_change-1]\n",
    "# correct x\n",
    "track_change = torch.tensor([38, 87, 132, 170, 203, 229, 250],dtype=torch.int)\n",
    "sensor_pos_p5[0,track_change] = -sensor_pos_p5[0,track_change]\n",
    "sensor_pos_interp[:,1:-1:2] = sensor_pos_p5[:,:-1]\n",
    "sensor_pos_interp = sensor_pos_interp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_collection import DNNSinogramSR, Sine, split_into_patches, reconstruct_from_patches, interpolate, FullyDenseUNet, ResNet, UNETMODIFIED,MirroredReLU,AbsoluteReLU\n",
    "import torch.nn as nn\n",
    "\n",
    "# print(f\"input shape: {256, 241}\")\n",
    "def predict(inp,netloc,is01=False):\n",
    "    inp = interpolate(inp.unsqueeze(0).unsqueeze(0),(inp.shape[0]*2,inp.shape[1]),mode='bilinear').squeeze(0).squeeze(0)\n",
    "    inp_max = inp.abs().max()\n",
    "    inp /= inp_max\n",
    "    if is01:\n",
    "        inp += 1\n",
    "    out = netloc(inp.unsqueeze(0).unsqueeze(0).to(device)).squeeze(0).squeeze(0).detach()\n",
    "    if is01:\n",
    "        out -= 1\n",
    "    out[0::2,:] = out[0::2,:] / out[0::2,:].max() #\n",
    "    out[1::2,:] = out[1::2,:] / out[1::2,:].max() # normalize the fully predicted signal, individually\n",
    "    out = out*inp_max\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advance_plot(depth_mm,thickness,byslice_mm,bxslice_mm,isMax=False,isDepth=False):\n",
    "    global volPA, volUS\n",
    "    plt.figure(figsize=(20,5))\n",
    "    depth = int((depth_mm + r) * imsz / (2*r))\n",
    "    byslice = int((byslice_mm + r) * imsz / (2*r))\n",
    "    bxslice = int((bxslice_mm + r) * imsz / (2*r))\n",
    "    image3D = volPA.abs().cpu()\n",
    "    image3DUS = 20*np.log10(volUS.abs().cpu().numpy() + 1e-6)\n",
    "    image3DUS = image3DUS - image3DUS.max()\n",
    "    \n",
    "    \n",
    "    plt.subplot(131)\n",
    "    if not isMax and not isDepth:\n",
    "        image = image3D[:,:,depth]\n",
    "        image = image / image.max()\n",
    "        cmap = 'hot'\n",
    "    else:\n",
    "        if isMax:\n",
    "            image = image3D.max(2).values\n",
    "            image = image / image.max()\n",
    "            cmap='hot'\n",
    "        elif isDepth:\n",
    "            image = depthImage(image3D.numpy(),0,False,True)\n",
    "            cmap='hot'\n",
    "    imageUS = image3DUS[:,:,depth]\n",
    "    imUS = plt.imshow(np.rot90(imageUS),cmap='gray',origin='upper',vmin=-60,vmax=0)\n",
    "    im   = plt.imshow(np.rot90(image),cmap=cmap,origin='upper',alpha=1.0)\n",
    "    plt.xticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(-r,r,5)])\n",
    "    plt.yticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(r,-r,5)])\n",
    "    plt.xlabel(\"x (mm)\")\n",
    "    plt.ylabel(\"y (mm)\")\n",
    "    plt.axhline(imsz-byslice,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.axvline(bxslice,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.clim(0, 1.0)\n",
    "    plt.colorbar(im)\n",
    "    plt.title(f\"d={depth}, surface={thickness:.2f} mm\")\n",
    "\n",
    "    plt.subplot(132)\n",
    "    if not isMax:\n",
    "        image = image3D[:,byslice,:]\n",
    "    else:\n",
    "        image = image3D.max(1).values\n",
    "    image = image / image.max()\n",
    "    imageUS = image3DUS[:,byslice,:]\n",
    "\n",
    "    imUS    = plt.imshow(np.rot90(imageUS),cmap='gray',origin='upper',vmin=-60,vmax=0)\n",
    "    im      = plt.imshow(np.rot90(image),cmap='hot',origin='upper',alpha=1.0)\n",
    "    \n",
    "    plt.xticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(-r,r,5)])\n",
    "    plt.yticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(r,-r,5)])\n",
    "    plt.xlabel(\"x (mm)\")\n",
    "    plt.ylabel(\"z (mm)\")\n",
    "    plt.axhline(imsz-depth,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.axvline(bxslice,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.colorbar(im)\n",
    "    plt.title(f\"y={byslice}\")\n",
    "\n",
    "    plt.subplot(133)\n",
    "    if not isMax:\n",
    "        image = image3D[bxslice,:,:]\n",
    "    else:\n",
    "        image = image3D.max(0).values\n",
    "    \n",
    "    image = image / image.max()\n",
    "    imageUS = image3DUS[bxslice,:,:]\n",
    "    imUS    = plt.imshow(np.rot90(imageUS),cmap='gray',origin='upper',vmin=-60,vmax=0)\n",
    "    im      = plt.imshow((np.rot90(image)),cmap='hot',origin='upper',alpha=1.0)\n",
    "    plt.xticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(-r,r,5)])\n",
    "    plt.yticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(r,-r,5)])\n",
    "    plt.xlabel(\"y (mm)\")\n",
    "    plt.ylabel(\"z (mm)\")\n",
    "    plt.axhline(imsz-depth,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.axvline(byslice,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.clim(0, 1.0)\n",
    "    plt.colorbar(im)\n",
    "    plt.title(f\"x={bxslice}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def advance_plot2(depth_mm,thickness,byslice_mm,bxslice_mm,isMax=False,isDepth=False):\n",
    "    global volPA, volUS\n",
    "    plt.figure(figsize=(20,5))\n",
    "    depth = int((depth_mm + r) * imsz / (2*r))\n",
    "    byslice = int((byslice_mm + r) * imsz / (2*r))\n",
    "    bxslice = int((bxslice_mm + r) * imsz / (2*r))\n",
    "    image3D = volPA.abs().cpu()\n",
    "    image3DUS = 20*np.log10(volUS.abs().cpu().numpy() + 1e-6)\n",
    "    image3DUS = image3DUS - image3DUS.max()\n",
    "    \n",
    "    \n",
    "    plt.subplot(131)\n",
    "    if not isMax and not isDepth:\n",
    "        image = image3D[:,:,depth]\n",
    "        image = image / image.max()\n",
    "        cmap = 'hot'\n",
    "    else:\n",
    "        if isMax:\n",
    "            image = image3D.max(2).values\n",
    "            image = image / image.max()\n",
    "            cmap='hot'\n",
    "        elif isDepth:\n",
    "            image = depthImage(image3D.numpy(),0,False,True)\n",
    "            cmap='hot'\n",
    "    imageUS = image3DUS[:,:,depth]\n",
    "    imUS = plt.imshow(np.rot90(imageUS),cmap='gray',origin='upper',vmin=-60,vmax=0)\n",
    "    im   = plt.imshow((image),cmap=cmap,origin='upper',alpha=1.0)\n",
    "    # plt.xticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(-r,r,5)])\n",
    "    # plt.yticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(r,-r,5)])\n",
    "    plt.xlabel(\"x (mm)\")\n",
    "    plt.ylabel(\"y (mm)\")\n",
    "    # plt.axhline(imsz-byslice,c='g',linestyle='--',alpha=0.5)\n",
    "    # plt.axvline(bxslice,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.clim(0, 1.0)\n",
    "    plt.colorbar(im)\n",
    "    # plt.title(f\"d={depth}, surface={thickness:.2f} mm\")\n",
    "\n",
    "    plt.subplot(132)\n",
    "    if not isMax:\n",
    "        image = image3D[:,byslice,:]\n",
    "    else:\n",
    "        image = image3D.max(1).values\n",
    "    image = image / image.max()\n",
    "    imageUS = image3DUS[:,byslice,:]\n",
    "\n",
    "    imUS    = plt.imshow(np.rot90(imageUS),cmap='gray',origin='upper',vmin=-60,vmax=0)\n",
    "    im      = plt.imshow(image,cmap='hot',origin='upper',alpha=1.0)\n",
    "    \n",
    "    # plt.xticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(-r,r,5)])\n",
    "    # plt.yticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(r,-r,5)])\n",
    "    plt.xlabel(\"y (mm)\")\n",
    "    plt.ylabel(\"z (mm)\")\n",
    "    # plt.axhline(imsz-depth,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.colorbar(im)\n",
    "    # plt.title(f\"y={byslice}\")\n",
    "\n",
    "    plt.subplot(133)\n",
    "    if not isMax:\n",
    "        image = image3D[bxslice,:,:]\n",
    "    else:\n",
    "        image = image3D.max(0).values\n",
    "    \n",
    "    image = image / image.max()\n",
    "    imageUS = image3DUS[bxslice,:,:]\n",
    "    imUS    = plt.imshow(np.rot90(imageUS),cmap='gray',origin='upper',vmin=-60,vmax=0)\n",
    "    im      = plt.imshow(image,cmap='hot',origin='upper',alpha=1.0)\n",
    "    # plt.xticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(-r,r,5)])\n",
    "    # plt.yticks(np.linspace(0,imsz,5),[f\"{x:.1f}\" for x in np.linspace(r,-r,5)])\n",
    "    plt.xlabel(\"x (mm)\")\n",
    "    plt.ylabel(\"z (mm)\")\n",
    "    # plt.axhline(imsz-depth,c='g',linestyle='--',alpha=0.5)\n",
    "    plt.clim(0, 1.0)\n",
    "    plt.colorbar(im)\n",
    "    # plt.title(f\"x={bxslice}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./dataset/leaf/\" ; datanum = 20; offset=91\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf         = np.load('./hardware/psf_recorded.npy')\n",
    "\n",
    "signal_power = (psf.real**2).mean()\n",
    "snr_linear = 10 ** (30 / 10)\n",
    "noise_power = signal_power / snr_linear\n",
    "noise_std = noise_power**0.5\n",
    "noisefloor = np.random.normal(size=psf.real.shape) * noise_std\n",
    "\n",
    "psf.real = psf.real / abs(psf).max()\n",
    "psf.imag = psf.imag / abs(psf).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "modelfolder = 'published'\n",
    "def get_model(netMethod):\n",
    "    netloc = None\n",
    "    NSpheres = 4\n",
    "    if netMethod=='SINESINE':\n",
    "        netloc         = DNNSinogramSR(\n",
    "            Sine(),\n",
    "            Sine(),\n",
    "            f=64\n",
    "        ).to(device) # OG model\n",
    "\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/unet_sine_sine.pth\")\n",
    "\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod=='RELUELU':\n",
    "        netloc         = DNNSinogramSR(\n",
    "            nn.ReLU(),\n",
    "            nn.ELU(),\n",
    "            f=64,\n",
    "        ).to(device) # OG model\n",
    "\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/unet_relu_elu.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod=='RELUSINE':\n",
    "        netloc         = DNNSinogramSR(\n",
    "            nn.ReLU(),\n",
    "            Sine(),\n",
    "            f=64,\n",
    "        ).to(device) # OG model\n",
    "\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/unet_relu_sine.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    \n",
    "    elif netMethod=='RELURELU-01':\n",
    "        netloc         = DNNSinogramSR(\n",
    "            nn.ReLU(),\n",
    "            nn.ReLU(),\n",
    "            f=64,\n",
    "        ).to(device) # OG model\n",
    "\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/unet_relu_relu_01.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "\n",
    "    elif netMethod=='No Activation':\n",
    "        netloc         = DNNSinogramSR(\n",
    "            nn.Identity(),\n",
    "            nn.Identity()\n",
    "        ).to(device) # OG model\n",
    "\n",
    "        PATH        = os.path.expanduser(f\"./trained_model/{modelfolder}/identity/modelNoFK_0_{NSpheres}.pth\")\n",
    "\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod=='ResNet-RELU':\n",
    "        netloc  = ResNet(1,64,(3,3),1,nn.ReLU(),nn.ELU(),False).to(device)\n",
    "        PATH    = os.path.expanduser(f\"./trained_model/{modelfolder}/resnet_relu.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH,weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod=='ResNet-SINE':\n",
    "        netloc  = ResNet(1,64,(3,3),1,Sine(),Sine(),False).to(device)\n",
    "        PATH    = os.path.expanduser(f\"./trained_model/{modelfolder}/resnet_sine.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH,weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "\n",
    "    elif netMethod=='FDUNET-SINE':\n",
    "        netloc          = FullyDenseUNet(in_channels=64,feature_map=64,growth_rate=16,activ_func=Sine(),activ_func2=Sine()).to(device)\n",
    "\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/fdunet_sine_sine.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod=='FDUNET-SINE-32':\n",
    "        netloc          = FullyDenseUNet(in_channels=32,feature_map=32,growth_rate=32,activ_func=Sine(),activ_func2=Sine()).to(device)\n",
    "\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/fdunet_sine_sine_f32.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod=='FDUNET-RELUELU':\n",
    "        netloc          = FullyDenseUNet(in_channels=64,feature_map=64,growth_rate=16,activ_func=nn.ReLU(),activ_func2=nn.ELU()).to(device)\n",
    "\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/fdunet_relu_elu.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod=='FDUNET-RELU-RELU-01':\n",
    "        netloc          = FullyDenseUNet(in_channels=64,feature_map=64,growth_rate=16,activ_func=nn.ReLU(),activ_func2=nn.ReLU()).to(device)\n",
    "\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/fdunet_relu_relu_01.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "\n",
    "    elif netMethod == 'Linear Interpolation':\n",
    "        netloc = nn.Identity().to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod == 'ResNet-RELU-01':\n",
    "        netloc  = ResNet(1,64,(3,3),1,nn.ReLU(),nn.ELU(),False).to(device)\n",
    "        PATH    = os.path.expanduser(f\"./trained_model/{modelfolder}/resnet_relu_01.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH,weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "\n",
    "    elif netMethod == \"MIRRORED-RELU\":\n",
    "        netloc         = UNETMODIFIED(\n",
    "            MirroredReLU(),\n",
    "            MirroredReLU(),\n",
    "            f=64,\n",
    "            ).to(device)\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/unet_mirrored_relu.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    elif netMethod == \"ABSOLUTE-RELU\":\n",
    "        netloc         = UNETMODIFIED(\n",
    "            AbsoluteReLU(),\n",
    "            AbsoluteReLU(),\n",
    "            f=64,\n",
    "            ).to(device)\n",
    "        PATH          = os.path.expanduser(f\"./trained_model/{modelfolder}/unet_absolute_relu_f64.pth\")\n",
    "        netloc.load_state_dict(torch.load(PATH, weights_only=True,map_location='cuda'))\n",
    "        netloc = netloc.to(device)\n",
    "        netloc.eval()\n",
    "    \n",
    "    return netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2520994ce9e4b639ba897499d4ed650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, description='File', max=0), IntSlider(value=1, description='I…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16230a04489b4684bd4151b5b4bffa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick check, each frame in image\n",
    "params = {\n",
    "    'is_UBP':False,\n",
    "    'is_WIENER':False,\n",
    "    'is_DIRECTIVITY':False,\n",
    "    'is_SVD':False,\n",
    "    'SVD_THS':3,\n",
    "    'WIENER_METHOD':'FREQ',\n",
    "    'WIENER_REG':1e-2,\n",
    "    'POST_SVD':False,\n",
    "    'POST_SVD_THS':2,\n",
    "    'BEAMFORM_TYPE':'DAS',\n",
    "    'is_CF':False,\n",
    "    'SENSOR_POS':sensor_pos,\n",
    "    'cPA':None,\n",
    "    'CFmethod':'CF'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "prediction = None\n",
    "outp = None\n",
    "AlldatPA2 = None\n",
    "\n",
    "\n",
    "\n",
    "def update_plots(file,interframe,cPA, cUS,depth_mm,\n",
    "                 byslice_mm,bxslice_mm,isINTERP,netMethod,\n",
    "                 isMax,isDepth,NSpheres,is_DIRECTIVITY,is_Wiener,\n",
    "                 is_US,is_PA,is_CF,is_FK):\n",
    "    global AlldatPA2, volPA, volUS, prediction, outp, AlldatPA_raw, netname\n",
    "    \n",
    "    if isINTERP:\n",
    "        netname = f\"{netMethod}_c{int(cPA)}mps_{file}_{interframe}\"\n",
    "    else:\n",
    "        if is_Wiener:\n",
    "            netname = f\"WIENER_c{int(cPA)}mps_{file}_{interframe}\"\n",
    "        else:\n",
    "            netname = f\"RAW_c{int(cPA)}mps_{file}_{interframe}\"\n",
    "            \n",
    "    AlldatPA_raw    = load_vrs_data(f\"{folder}TestFile{str(file + offset).zfill(3)}.vrs\",datanum=datanum) # either 20, 30\n",
    "    sig             = abs(hilbert(AlldatPA_raw[interframe,:,245,0]))\n",
    "    idxmax          = np.argmax(sig[500:]) + 500\n",
    "    thickness       = 30 - (idxmax * cPA / Fs)*0.5*1e3# in mm\n",
    "    # depth calculation\n",
    "    d = (3*(r**2))**0.5\n",
    "    # PA\n",
    "    start_time_PA  = np.floor((((sensor_pos.cpu().numpy()[:,0]**2).sum())**0.5 - d) * 1e-3 * Fs / cPA).astype(int) \n",
    "    end_time_PA    =  np.ceil((((sensor_pos.cpu().numpy()[:,0]**2).sum())**0.5 + d) * 1e-3 * Fs / cPA).astype(int)\n",
    "    print(end_time_PA - start_time_PA)\n",
    "    \n",
    "\n",
    "    residue = (256 - (end_time_PA - start_time_PA))\n",
    "\n",
    "    start_time_PA -= residue //2 \n",
    "    end_time_PA += residue//2 + np.mod(residue,2)\n",
    "    print(start_time_PA,end_time_PA)\n",
    "    AlldatPA = AlldatPA_raw.copy()[:,start_time_PA:end_time_PA,:,:] * 1e-3\n",
    "    # AlldatPA = AlldatPA / AlldatPA.max()\n",
    "\n",
    "    # AlldatPA2 = fk_filter(AlldatPA[interframe*3+2,:,:,0])\n",
    "    if is_FK:\n",
    "        AlldatPA2 = fk_filter(AlldatPA[interframe,:,:,0])\n",
    "    else:\n",
    "        AlldatPA2 = (AlldatPA[interframe,:,:,0])\n",
    "    # AlldatPA2 = AlldatPA[interframe*3+2,:,:,0]\n",
    "    # AlldatPA2 = AlldatPA[interframe,:,:,0]\n",
    "    # AlldatPA2 = AlldatPA[2::3,:,:,0].mean(0)\n",
    "\n",
    "    params['cPA']           = torch.tensor(cPA,dtype=torch.float) # overwrite\n",
    "    params['start_time_PA'] = torch.tensor(start_time_PA,dtype=torch.float) # overwrite\n",
    "    params['end_time_PA']   = torch.tensor(end_time_PA,dtype=torch.float) # overwrite\n",
    "    params['is_DIRECTIVITY']= is_DIRECTIVITY\n",
    "    params['is_WIENER']     = False\n",
    "    params['is_CF']         = is_CF\n",
    "\n",
    "    if isINTERP: # if true, then use interpolation\n",
    "        params['BEAMFORM_TYPE'] = 'DAS-INTERP'\n",
    "        params['SENSOR_POS'] = sensor_pos_interp\n",
    "    else:\n",
    "        params['BEAMFORM_TYPE'] = 'DAS'\n",
    "        params['SENSOR_POS'] = sensor_pos\n",
    "\n",
    "    netloc = get_model(netMethod)\n",
    "\n",
    "    if 'INTERP' in params['BEAMFORM_TYPE']:\n",
    "        if netMethod == 'Linear Interpolation':\n",
    "            params['is_WIENER']     = is_Wiener\n",
    "        # AlldatPA2 = fk_filter(AlldatPA[interframe*2+1,:,:,0])\n",
    "        if '01' in netMethod:\n",
    "            is01 = True\n",
    "        else:\n",
    "            is01=False\n",
    "        torch.cuda.synchronize();start_time = time.time()\n",
    "        prediction = predict(torch.tensor(AlldatPA2.T,dtype=torch.float),netloc,is01).cpu().numpy()\n",
    "        torch.cuda.synchronize();end_time = time.time()\n",
    "        elapsed_time_pred = (end_time - start_time) * 1_000\n",
    "\n",
    "        volPA = quickPAbeamform(prediction,params).cpu()\n",
    "        torch.cuda.synchronize();end_time = time.time()\n",
    "        elapsed_beamform = (end_time - start_time) * 1_000\n",
    "\n",
    "        print(f\"{elapsed_time_pred:.2f} ms, {elapsed_beamform:.2f} ms\")\n",
    "    else:\n",
    "        torch.cuda.synchronize();start_time = time.time()\n",
    "        params['is_WIENER']     = is_Wiener\n",
    "        volPA = quickPAbeamform((torch.tensor(AlldatPA2.T,dtype=torch.float)).cpu().numpy(),params).cpu()\n",
    "        torch.cuda.synchronize();end_time = time.time()\n",
    "        elapsed_beamform = (end_time - start_time) * 1_000\n",
    "        print(f\" {elapsed_beamform:.2f} ms\")\n",
    "\n",
    "    \n",
    "\n",
    "    if is_US:\n",
    "        # AlldatUS    = AlldatPA_raw[[x for x in range(30) if x % 3 != 2],:,:,0]\n",
    "        AlldatUS    = AlldatPA_raw[0,:,:,0]\n",
    "        AlldatUS    = np.expand_dims(AlldatUS,axis=0)\n",
    "\n",
    "        volUS       = beamformUS(AlldatUS,cUS,is_CF)\n",
    "    else:\n",
    "        volUS       = torch.zeros((imsz,imsz,imsz))\n",
    "\n",
    "    if not is_PA:\n",
    "        volPA       = torch.zeros((imsz,imsz,imsz))\n",
    "\n",
    "    advance_plot(depth_mm,thickness,byslice_mm,bxslice_mm,isMax,isDepth)\n",
    "\n",
    "    # IUSvisualization()\n",
    "    # plt.imshow(torch.rot90(volPA.abs()[:,35,:]),cmap='hot') # .max(1).values\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "def on_button_click(b):\n",
    "    # 06022025_Leaf546nm\n",
    "    # np.save(f\"./dataset/27012025/individualdataset/{modelfolder}_FK/{netname}.npy\",volPA.abs().numpy())\n",
    "    np.save(f\"./dataset/06022025_Leaf546nm/{modelfolder}_FK/{netname}_.npy\",volPA.abs().numpy())\n",
    "save_button = Button(description=\"Save Data\")\n",
    "save_button.on_click(on_button_click)\n",
    "\n",
    "file_slider = IntSlider(min=0,max=len(os.listdir(folder))-1,value=1,description='File')\n",
    "interframe_slider = IntSlider(min=0,max=30,value=1,description='Interframe')\n",
    "cPAslider = FloatSlider(min=1400,max=1540,value=1475,description='c PA')\n",
    "cUSslider = FloatSlider(min=1400,max=1540,value=1475,description='c US')\n",
    "\n",
    "\n",
    "depth_slider = FloatSlider(min=-r, max=r, step=0.025, continuous_update=True,description='Z slice')\n",
    "byslice_slider = FloatSlider(min=-r, max=r, step=0.025, continuous_update=True,description='Y slice')\n",
    "bxslice_slider = FloatSlider(min=-r, max=r, step=0.025, continuous_update=True,description='X slice')\n",
    "method_button = ToggleButton(value=False,description='INTERP')\n",
    "netMethod_select = Dropdown(\n",
    "    options=[ 'ResNet-RELU','ResNet-RELU-01' ,\n",
    "             'ResNet-SINE', 'SINESINE', 'RELUELU','RELUSINE',\n",
    "               'RELURELU-01', 'FDUNET-SINE', 'FDUNET-RELUELU','FDUNET-RELU-RELU-01',\n",
    "               'MIRRORED-RELU','ABSOLUTE-RELU',\n",
    "                 'No Activation', 'Linear Interpolation'],\n",
    "    value='No Activation',\n",
    "    description='NET:',\n",
    "    disabled=False\n",
    ")\n",
    "netNSpheres_select = Dropdown(\n",
    "    options=['1','2','3','4', '8', '16','32'],\n",
    "    value='4',\n",
    "    description='NSpheres:',\n",
    "    disabled=False\n",
    ")\n",
    "ismax_button = ToggleButton(value=False,description='USE MAX')\n",
    "isdep_button = ToggleButton(value=False,description='DEPTH (HIGH=FOCAL)')\n",
    "isdirectivity_button = ToggleButton(value=False,description='Directivity')\n",
    "is_wiener_button = ToggleButton(value=False,description='Wiener')\n",
    "is_US_button = ToggleButton(value=False,description='US')\n",
    "is_PA_button = ToggleButton(value=True,description='PA')\n",
    "is_CF_button = ToggleButton(value=True,description='CF')\n",
    "is_FK_button = ToggleButton(value=True,description='FK')\n",
    "\n",
    "\n",
    "col1 = VBox([file_slider, interframe_slider, cPAslider, cUSslider])  # First column\n",
    "col2 = VBox([depth_slider, byslice_slider, bxslice_slider])  # Second column\n",
    "col3 = VBox([method_button,netMethod_select,netNSpheres_select])  # Third column\n",
    "col4 = VBox([ismax_button,isdep_button,isdirectivity_button,save_button])  # Third column\n",
    "col5 = VBox([is_wiener_button,is_US_button,is_PA_button,is_CF_button])\n",
    "interactive_plot = interactive_output(\n",
    "    update_plots,{\n",
    "            'file':file_slider,\n",
    "            'interframe':interframe_slider, \n",
    "            'cPA':cPAslider,\n",
    "            'cUS':cUSslider,\n",
    "            'depth_mm':depth_slider,\n",
    "            'byslice_mm':byslice_slider,\n",
    "            'bxslice_mm':bxslice_slider,\n",
    "            'isINTERP':method_button,\n",
    "            'netMethod':netMethod_select,\n",
    "            'isMax':ismax_button,\n",
    "            'isDepth':isdep_button,\n",
    "            'NSpheres':netNSpheres_select,\n",
    "            'is_DIRECTIVITY':isdirectivity_button,\n",
    "            'is_Wiener':is_wiener_button,\n",
    "            'is_US':is_US_button,\n",
    "            'is_PA':is_PA_button,\n",
    "            'is_CF':is_CF_button,\n",
    "            'is_FK':is_FK_button\n",
    "        }\n",
    "    )\n",
    "\n",
    "display(HBox([col1, col2, col3,col4,col5,is_FK_button]))\n",
    "display(\n",
    "    interactive_plot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
